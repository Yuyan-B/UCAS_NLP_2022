{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_trainset=pd.read_csv(\"E:/研一/上课/自然语言处理/大作业/UCAS_NLP_2022/data/starting_ki/train_all_tasks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_oversample=pd_trainset[(pd_trainset['label_category']=='2. derogation')|(pd_trainset['label_category']=='3. animosity')]\n",
    "for i in range(4):\n",
    "    pd_oversample= pd.concat([pd_oversample,pd_trainset[(pd_trainset['label_category']=='1. threats, plans to harm and incitement')]])\n",
    "    pd_oversample=pd.concat([pd_oversample,pd_trainset[(pd_trainset['label_category']=='4. prejudiced discussions')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_category\n",
       "1. threats, plans to harm and incitement    1240\n",
       "2. derogation                               1590\n",
       "3. animosity                                1165\n",
       "4. prejudiced discussions                   1332\n",
       "Name: rewire_id, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_oversample[pd_oversample['label_sexist']=='sexist'].groupby('label_category')['rewire_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_oversample.to_csv(f'./data/oversampleB.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_oversampleC=pd_trainset[pd_trainset['label_vector'].isin(['2.1 descriptive attacks','2.2 aggressive and emotive attacks','3.1 casual use of gendered slurs, profanities, and insults','3.2 immutable gender differences and gender stereotypes'])]\n",
    "for i in range(12):\n",
    "    pd_oversampleC= pd.concat([pd_oversampleC,pd_trainset[(pd_trainset['label_vector']=='1.1 threats of harm')]])\n",
    "    \n",
    "for i in range(3):\n",
    "    pd_oversampleC= pd.concat([pd_oversampleC,pd_trainset[(pd_trainset['label_vector']=='1.2 incitement and encouragement of harm')]])\n",
    "    pd_oversampleC= pd.concat([pd_oversampleC,pd_trainset[(pd_trainset['label_vector']=='2.3 dehumanising attacks & overt sexual objectification')]])\n",
    "    pd_oversampleC= pd.concat([pd_oversampleC,pd_trainset[(pd_trainset['label_vector']=='4.2 supporting systemic discrimination against women as a group')]])\n",
    "    \n",
    "for i in range(11):\n",
    "    pd_oversampleC= pd.concat([pd_oversampleC,pd_trainset[(pd_trainset['label_vector']=='3.3 backhanded gendered compliments')]])\n",
    "    \n",
    "for i in range(14):\n",
    "    pd_oversampleC= pd.concat([pd_oversampleC,pd_trainset[(pd_trainset['label_vector']=='3.4 condescending explanations or unwelcome advice')]])\n",
    "    \n",
    "for i in range(9):\n",
    "    pd_oversampleC=pd.concat([pd_oversampleC,pd_trainset[(pd_trainset['label_vector']=='4.1 supporting mistreatment of individual women')]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_vector\n",
       "1.1 threats of harm                                                672\n",
       "1.2 incitement and encouragement of harm                           762\n",
       "2.1 descriptive attacks                                            717\n",
       "2.2 aggressive and emotive attacks                                 673\n",
       "2.3 dehumanising attacks & overt sexual objectification            600\n",
       "3.1 casual use of gendered slurs, profanities, and insults         637\n",
       "3.2 immutable gender differences and gender stereotypes            417\n",
       "3.3 backhanded gendered compliments                                704\n",
       "3.4 condescending explanations or unwelcome advice                 658\n",
       "4.1 supporting mistreatment of individual women                    675\n",
       "4.2 supporting systemic discrimination against women as a group    774\n",
       "Name: rewire_id, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_oversampleC[pd_oversampleC['label_sexist']=='sexist'].groupby('label_vector')['rewire_id'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_oversampleC.to_csv(f'./data/oversampleC.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed9f1a28aade276a92d1f03ffda25688ea46a43468a4597dfbd26b75bcb7e3a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
